\subsection{Technical Setup and Automated Assessment}\label{sec:tech_setup_test}

\paragraph{Automated Assessment}
In WS19, we used an improved version of
the testing infrastructure introduced in~\cite{next_1100}.
However, this system could neither manage online exams nor mark non-programming tasks.
We thus switched to a newly written open-source
tool developed at TUM called ArTEMiS~\cite{artemis}.
ArTEMis is a highly scalable, automated assessment management system and is programming language independent --
it only expects test runners to produce tests results
adhering to the Apache Ant JUnit XML schema.
It already offered support for a few imperative programming languages,
and we added support for Haskell.\footnote{It now also supports OCaml.}

As ArTEMis takes care of most things,
including automated test execution and score management,
and offers an exam mode and good support for grading non-programming tasks,
the only thing that was left to do was writing the testing code.
For the most part, we verified the results computed
by a student's submission by comparing them to those
computed by a sample solution written by us.
In some cases, we also tested for efficiency using timeouts.
Our tests were powered by the following libraries:
\begin{enumerate}
  \item QuickCheck \cite{quickcheck}:
  Although QuickCheck can automatically generate test data (using the typeclass \mintinline{Haskell}{Arbitrary}),
  most tests and benchmarks used custom input generators.
  This was necessary to increase coverage and eliminate non-applicable inputs for tests with preconditions.
  We also used custom shrinkers to provide better feedback to students in case of a failure.
  In both cases, the flexible combinators provided by QuickCheck made this a straightforward task.
  \item SmallCheck \cite{smallcheck}: The exhaustive testing facilities provided by SmallCheck mainly served
    as a complementary tool that provided small counterexamples for, in many cases, obvious deficiencies.
  \item Tasty\footnote{\url{https://hackage.haskell.org/package/tasty}}: We used Tasty to put QuickCheck, SmallCheck, unit tests, and the checking of ``Check Your Proof'' proofs (see \cref{sec:cyp}) into one common framework that is capable of generating results interpretable by ArTEMiS.
  We used the unit testing facilities of Tasty to complement our tests with corner cases.
  Integration of proof checking was pleasantly straightforward:
  one only has to provide a suitable instance for Tasty's \mintinline{Haskell}{IsTest} typeclass.\footnote{The code can be found in the repository in \href{https://github.com/kappelmann/engaging-large-scale-functional-programming/tree/main/resources/io_mocking/typeclass}{resources/cyp\_integration/test/hs/Test.hs}}
  Moreover, Tasty supports timeouts for individual test cases.
  solving the issue of truncated test reports mentioned in~\cite{next_1100}.
\end{enumerate}

\paragraph{Development Environment and Online Tutorials}
In previous iterations,
there were no recommendations for students regarding the development environment they should use for the practical part of the course.
However, due to the COVID-19 pandemic,
this was no longer an option:
we needed a way for students to share their code in read and write mode
to other peers (pair-programming) and teaching assistants (for feedback purposes) during online tutorials.
Moreover, as explained in \cref{sec:engagement},
we wanted students to use a linter.
Finally, we had negative experiences with students
installing no compiler at all
and instead (mis)using our submission server as a compiler backend.
We thus introduced a strict policy
for the technical setup to be used during
the tutorials.
Detailed installation instructions can be found online\footnote{\url{https://www21.in.tum.de/teaching/fpv/WS20/installation.html}}.
% and an extended description and report will follow in the final version of this article.
Here we briefly list the key components and our experiences:
\begin{enumerate}
  \item IDE: We used VSCodium\footnote{VSCodium provides free open-source software binaries of VSCode \url{https://vscodium.com/}} due to its cross-platform support,
    rich library of extensions,
    widespread adoption,
    and free open-source software philosophy.
    We did not receive any negative feedback by students
    and, besides few exceptions, no major installation problems were reported.
  \item Build and dependency manager: We used Stack\footnote{\url{https://www.haskellstack.org/}} for these purposes.
    Since Stack provides curated sets of packages and compiler versions that are checked for compatibility,
    deterministic builds are guaranteed.
    Students hence showed little struggle to compile and execute their programs.
  \item Linter: We used HLint\footnote{\url{https://github.com/ndmitchell/hlint}}, which, among other things,
    provides suggestions for alternative functions
    and simplified code and spots redundancies.
    Students reacted curiously and positively to these suggestions
    and discussed them vividly during pair-programming sessions.
  \item API search engine: Due to Haskell's strong type system,
    searching its API by type signature often returns better results than searching for function names.
    For this purpose, we introduced Hoogle\footnote{\url{https://hoogle.haskell.org/}} to our students and let them install an extension that integrates Hoogle searches into their IDE.
    Unfortunately, we have no data to report on whether this enriched students' programming~experiences.
  \item Real-time collaboration: We used VSLiveShare\footnote{\url{https://visualstudio.microsoft.com/services/live-share/}} to run our pair-programming sessions (groups of 3--4 students).
    We can report positively on its connection stability and usability.
    Unfortunately, the plugin requires a Microsoft or GitHub account,
    but since almost all students
    already signed up to the latter before,
    this requirement passed uncontroversially.
    Nevertheless, for future iterations,
    we plan to investigate open-source alternatives.
\end{enumerate}

All in all, we can report positively on the setup.
% We have experience with running online tutorials for other large lectures and can testify that
% the system in this paper worked best in technical as well as social aspects.
Students were more knowledgeable
about their programming environment (compilation, dependency management, etc.) than in previous iterations.
Misappropriation of the submission server as a compiler backend also stopped.
