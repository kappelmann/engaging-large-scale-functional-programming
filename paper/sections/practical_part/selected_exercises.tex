\subsection{Selected Exercises and Tools}\label{sec:selected_exercises}


\begin{figure*}[t!]

\centering
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/chainreaction.png}
  \caption{Game tournaments}
  \label{fig:chainreaction}
\end{subfigure}%
~
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/haskell_art.png}
  \caption{Art generation}
\end{subfigure}
~
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \begin{tikzpicture}[scale=0.65]
  \begin{axis}[
    minor tick num=1,
    samples=120,
    axis y line=left,
    axis x line=middle
    ]
    \addplot+[domain=0:10, mark=none, teal]
      coordinates {(0,0) (2, 1)};
    \addplot+[domain=0:10, mark=none, blue]
      coordinates {(2,1) (3, 0.5)};
    \addplot+[domain=0:10, mark=none, purple]
      coordinates {(3, 0.5) (7.5, 0.5)};
    \addplot+[domain=0:10, mark=none, orange]
      coordinates {(7.5, 0.5) (10, 0)};
    \addplot[densely dashed] coordinates {(2,0) (2,1)};
    \addplot[densely dashed] coordinates {(3,0) (3,0.5)};
    \addplot[densely dashed] coordinates {(7.5,0) (7.5,0.6)};
    \addplot[densely dashed] coordinates {(10,0) (10,0.6)};
    \addplot[->] coordinates {(0,0.9) (2,0.9)} node[midway, above, teal] {attack};
    \addplot[->] coordinates {(2,0.4) (3,0.4)} node[midway, below, blue] {decay};
    \addplot[->] coordinates {(6,0) (6,0.5)} node[midway,left, purple] {sustain};
    \addplot[<-] coordinates {(7.5,0.6) (10,0.6)} node[midway, below, orange] {release};
    \addplot[->] coordinates {(0,0.1) (10,0.1)} node[midway, above, olive] {duration};
  \end{axis}
  \end{tikzpicture}
  \caption{Music synthesis}
\end{subfigure}
\caption{Examples of exercises created as part of the course}
\end{figure*}

Many students at TUM have questioned the
applicability and usefulness
of functional languages after completing
the mandatory functional programming course.
We believe this is mainly due to two reasons:
\begin{enumerate*}[label=\arabic*)]
  \item introductory courses often stick
to simple algorithmic or mathematically inspired challenges and
\item side-effects (in particular I/O)
are often introduced rather late
in functional programming courses.
\end{enumerate*}

While we were able to introduce I/O midway through the course,
introducing it even earlier appeared difficult to us:
we think that students would be confused
if a ``special'' \mintinline{Haskell}{IO} type and \mintinline{Haskell}{do} notation were to
be introduced before they are comfortable
with the basic features of functional languages.
We thus focused on the other issue
and created exercises that go beyond
simple terminal applications.
Designing and implementing such exercises,
however, is labour-intensive.
As mentioned in \cref{sec:engagement},
we thus decided to reallocate resources and
let our student assistants help us with this work
rather than providing feedback for homework submissions.

This turned out to be a very fruitful idea:
the quality of our student assistants' work was often way above what we expected.
The one difficulty we faced was the mediocre quality of
tests written by most assistants
since they only had the rudimentary knowledge of QuickCheck taught as part of the course.
We thus hosted a workshop for them that explained
our testing infrastructure and best-practice
patterns when writing tests.
The quality of tests significantly increased following this workshop,
though we still had to polish them before publication.

We next introduce a few exercises and tools
that were created as part of the course.
They are available in this article's repository\footnote{\url{https://github.com/kappelmann/engaging-large-scale-functional-programming}},
next to our other exercises, including
a music synthesiser framework,
a turtle graphics framework,
an UNO framework,
and guided exercises for DPLL and resolution provers.
% Some further examples can be found on our competition blogs\footnote{\url{https://www21.in.tum.de/teaching/fpv/WS20/wettbewerb.html} (WS20) and
% \url{https://www21.in.tum.de/teaching/fpv/WS19/wettbewerb.html} (WS19)}.

\paragraph{Game Tournament Framework}
It has become a course tradition to run a game tournament over the Christmas break.
In this tournament, students are tasked with writing an AI for a board game that competes against the AIs of their fellow students.
To pass the homework sheet, it suffices to implement a basic strategy, but to score well in the competition, students came up with quite sophisticated strategies in past years.
The framework allows students to use statefulness and randomisation, so that there are few limits to the students' creativity.
% The best strategies usually use the minimax rule with alpha-beta-pruning and a clever evaluation function, which is particularly important in this setting because the game tree cannot be evaluated very far given the time limit for each submission in the tournament.

The tournament runs continuously for 2--3 weeks and the results are displayed on a website (see \cref{fig:chainreaction} for an example from WS20).
Students thus get reasonably quick feedback on how their strategy performs,
which keeps them engaged and allows them to improve their strategy iteratively.
The tournament became a popular feature of the course with 182 participating students in WS19 and 220 in WS20.

In our repository, we provide the framework along with code specific to the game from WS20, which is based on Chain Reaction\footnote{\url{ https://brilliant.org/wiki/chain-reaction-game/}}.
It runs a round-robin tournament,
collecting statistics for each game and player.
Instructions for adapting the framework to a different game can also be found in the repository.

\paragraph{Programming Contest Framework}\label{sec:contest}
To foster social interaction and diversify the bonus system,
we hosted an ACM-ICPC-like programming contest.
In such contests, students
participate in teams of 2--3,
solving as many programming challenges as possible in a given time frame,
and can check their ranking on a live scoreboard.
% At some point during the contest,
% the scoreboard gets frozen,
% and following the working time,
% solutions to all challenges are presented by the organisers.
% The final results are then revealed by unfreezing the scoreboard again.

We found existing solutions
to run such contests too complex for our purpose
and hence created a lightweight alternative.
Our framework continuously receives test results,
computes each team's score,
and displays the live scoreboard and task instructions on a website.
It is agnostic to the programming language and test runner used.
It expects tests results adhering to the Apache Ant JUnit XML schema,
but modifying it to support other formats is straightforward.
Deployment instructions can be found in this article's repository.

We ran an online iteration of the contest in WS20,
again using ArTEMiS as a test runner.
Teams were cooperating on their platform of choice
and were able to ask for clarifications on a dedicated online channel.
Our experiences are positive:
27 teams participated in the contest
and most stayed for the social hangout following it.
Using our framework,
the technical setup of the contest requires little time.
Some significant time, however,
must be spent on setting up the challenges,
tests, and solutions,
though plenty of them may be found
online by searching for other contests,
which one then may modify and reuse.
We recommend offering such contests
to programming course instructors in general.
% for every lecture concerned with programming concepts.

\input{sections/practical_part/io_mocking/io_mocking}

